## <center>配置训练文件夹

### 第一步：使用数据标注工具 (X-AnyLabeling)

1. 下载：
* **官方地址：** [https://github.com/CVHub520/X-AnyLabeling/releases](https://github.com/CVHub520/X-AnyLabeling/releases)
* **选择文件：**
找到最新的版本（比如 v2.x.x），在 "Assets" 里找到以 `.exe` 结尾的文件。
* CPU版本：`X-AnyLabeling-CPU-v...exe`
* GPU版本：需要通过 Python 环境安装 GPU 版
https://github.com/CVHub520/X-AnyLabeling/blob/main/docs/zh_cn/get_started.md

---


1. **启动软件**：在终端直接输入以下命令并回车：
```bash
anylabeling
```


2. **加载模型**：
* 点击左侧的 **“大脑”图标**。
* 选择你想用的模型（如 YOLOv8n）。


3. **切换至 GPU 运行**：
* 在弹出的模型加载窗口中，找到 **Device (设备)** 选项。
* **重要**：从 `CPU` 切换为 **`CUDA`**（如果选项变灰或消失，说明 `onnxruntime-gpu` 没装好）。
* 加载后，你会发现右下角的状态栏会显示 `CUDA` 字样。

---

### 第二步：准备数据集

1. **新建文件夹：** 在你的 `yolo_study` 文件夹下，建一个叫 `dataset` 的文件夹。
2. **拍照：** 拿出你的手机，对着你的**鼠标**（或者笔、水杯）拍 5 张不同角度的照片。
3. **上传：** 把这 5 张照片放进 `dataset` 文件夹里。

---

### 第三步：标注数据集
**1. 准备工作：**
   1. 进入 X-AnyLabeling，点击左上角的 **"Open Dir"**（打开目录），选择你存放图片的文件夹（比如之前的 `dataset`）。
   2. 点击左上角的 **"Change Output Dir"**（更改输出目录），建议选同一个文件夹，或者新建一个 `labels` 文件夹。

**2. 开启自动保存：**

* 点击菜单栏 **File** -> 勾选 **Auto Save**。这样你切图的时候就不用每次按 Ctrl+S 了。

---

### 第三部分：核心功能——AI 自动标注（杀手锏）

这是你选择它的原因。我们让 AI 帮你干苦力。

**1. 加载模型：**

* 看左侧工具栏，找到一个 **“大脑”形状的图标** (AI Mode)。
* 点击它，会弹出一个列表。
* 选择 **Model** -> **YOLOv8** -> **YOLOv8n** (最轻量，下载最快)。
* *第一次选会提示下载模型，点击 OK 等待下载完成。*



**2. 一键标注：**

* 模型加载完后，点击“大脑”图标下方的 **“运行”按钮**（或者快捷键 `Ctrl + J`）。
* **奇迹发生：** 软件会自动识别图中的物体（比如人、车等），并自动画好框！

**3. 你的工作：**

* **如果框对了：** 只需要把类别名字改一下（比如它识别成 `person`，你双击改成 `robot`）。
* **如果没框住：** 你再手动补画一下。

---

### 第四部分：手动标注与工具

如果是 AI 识别不出来的特殊物体（比如你们比赛的装甲板），你需要手动标。

**1. 画矩形框 (检测任务)：**

* 快捷键：**`R`** (Rectangle)。
* 按住鼠标左键拖拽画框。
* 输入类别名称（如 `armor`）。

**2. 画多边形 (分割任务 - 进阶)：**

* 如果你以后做图像分割（Image Segmentation），需要沿着物体轮廓描点。
* 快捷键：**`P`** (Polygon)。

**3. 旋转框 (OBB - 机器人竞赛常用)：**

* 有些比赛（如 RoboMaster）需要识别旋转的物体（俯视图）。
* X-AnyLabeling 支持旋转框，这在 LabelImg 里是做不到的。
* 工具栏里选择 **"Rotated Box"**。

---

### 第五步：导出为 YOLO 格式 (关键！)

X-AnyLabeling 默认保存的是 JSON 格式（包含很详细的信息），但 YOLO 训练需要的是 `.txt` 格式。

**你需要做一次“导出”操作：**

1. 标完所有图片后。
2. 点击菜单栏左上角的 **"Export"** (导出图标，通常在保存旁边)。
3. 选择导出格式：**"Export to YOLO"**。
4. 在弹出的设置里：
* **Class Name File:** 它可以自动生成，或者你导入之前的 `classes.txt`。
* **Output Dir:** 选择导出位置。


5. 点击 OK。

它会生成 `train/images`, `train/labels` 这样的标准结构，你可以直接把这个文件夹喂给 YOLOv8 训练！

---

### 第二步：准备数据集

1. **新建文件夹：** 在你的 `yolo_study` 文件夹下，建一个叫 `dataset` 的文件夹。
2. **拍照：** 拿出你的手机，对着你的**鼠标**（或者笔、水杯）拍 5 张不同角度的照片。
3. **上传：** 把这 5 张照片放进 `dataset` 文件夹里。

---

### 第三步：开始标注

1. **启动工具：**
在终端里输入 `labelimg` 并回车。这就打开了软件界面。
2. **关键设置（千万别漏）：**
* 看左侧工具栏，找到 **"PascalVOC"** 按钮。
* **点击它**，直到它变成 **"YOLO"**。
* *这非常重要！因为 YOLO 需要的是 .txt 格式，不是 .xml。*


3. **开始画框：**
* 点击左侧 **"Open Dir"** -> 选择你的 `dataset` 文件夹。
* 点击 **"Change Save Dir"** -> **也选择** `dataset` 文件夹（图片和标签放一起方便点）。
* 按键盘 **`w`** 键（快捷键），鼠标会变成十字。
* **框住**你的鼠标。
* 弹出的窗口里输入类别名：`mouse`。
* 按 **`Ctrl + S`** 保存。
* 按 **`d`** 键切换到下一张图。



把 5 张图都标完。完成后，去文件夹里看看，是不是每张 `.jpg` 旁边都多了一个同名的 `.txt` 文件？打开看看，里面应该是类似 `0 0.5 0.5 0.2 0.3` 的数字。

---

### 第四步：配置“寻宝地图” (data.yaml)

YOLO 需要一个说明书，告诉它去哪里找数据，以及有哪些类别。

在 `yolo_study` 文件夹下，新建一个文件 `my_data.yaml`，复制下面的内容进去：

```yaml
# 这里的路径要改成你实际的绝对路径
# 注意：Windows路径的反斜杠 \ 要改成正斜杠 / 或者双反斜杠 \\
path: E:/yolo_study/dataset  
train: .  # 因为我们只有5张图，就都拿来训练吧（偷懒做法）
val: .    # 验证集也用这几张

# 类别数量
nc: 1

# 类别名称（必须和你标注时写的名字一模一样）
names: ['mouse']

```

---

### 第五步：开始训练！

这是见证奇迹的时刻。虽然你是 CPU，但因为只有 5 张图，训练应该在 1-3 分钟内就能跑完。

新建一个 `train.py`，写入：

```python
from ultralytics import YOLO

# 1. 加载模型 (使用 nano 版本，速度最快)
model = YOLO('yolov8n.pt') 

# 2. 开始训练
# data: 你的 yaml 配置文件
# epochs: 训练几轮？演示用 20 轮就够了
# imgsz: 图片大小，640 是标准
results = model.train(data='my_data.yaml', epochs=20, imgsz=640)

```

**运行它：** `python train.py`

---

### 你的任务

现在就去动手试一下！
当你看到终端里出现进度条，并且每一轮（Epoch）结束后显示 `box_loss` 在下降，说明**你的机器正在学习认识鼠标**。

**等你跑完了，告诉我结果，我教你如何用这一套流程去处理你们机器人比赛的真实数据（成百上千张图）。**